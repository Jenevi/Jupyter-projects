{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e656be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ca2015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6edd3b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Lunar_lander_traning_set.pkl', 'rb') as f:\n",
    "    # Загружаем список из файла\n",
    "    training_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e100019e",
   "metadata": {},
   "source": [
    "Превратим входные данные из [observation, act, reward] в x = [concat(observation, one_hot_act)] Y = [reward]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f83d73b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dct = {}\n",
    "dct[0] = [1, 0, 0, 0]\n",
    "dct[1] = [0, 1, 0, 0]\n",
    "dct[2] = [0, 0, 1, 0]\n",
    "dct[3] = [0, 0, 0, 1]\n",
    "\n",
    "out = []\n",
    "Y = []\n",
    "for i in training_set:\n",
    "    temp = []\n",
    "    temp.extend(i[0])\n",
    "    temp.extend(dct[i[1]])\n",
    "    out.append(temp)\n",
    "    Y.append(i[-1])\n",
    "    \n",
    "x = torch.tensor(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eb9e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(8+4, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b4e50e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 1.1666e-01, -1.3776e-01,  2.7435e-01, -1.4441e-01,  1.7759e-01,\n",
       "                        9.4057e-02, -1.6692e-01,  1.0403e-01,  8.9803e-02, -2.2927e-01,\n",
       "                        1.7117e-01,  1.4381e-01],\n",
       "                      [-7.8118e-02,  2.6869e-02, -2.0532e-01, -1.1949e-01,  2.0646e-01,\n",
       "                       -1.9160e-01,  2.7204e-01,  2.3728e-01,  2.6993e-01,  1.5549e-01,\n",
       "                        2.4884e-01,  1.2151e-01],\n",
       "                      [ 2.0810e-01, -1.7578e-01,  1.4454e-01, -1.4577e-01,  4.6799e-03,\n",
       "                        1.0328e-01,  2.8814e-01, -2.7936e-01, -9.5666e-02, -1.4623e-01,\n",
       "                        2.9169e-02, -1.7091e-01],\n",
       "                      [ 2.5269e-01, -2.7338e-01,  2.7786e-01, -1.1533e-01,  8.8623e-02,\n",
       "                       -1.8729e-02, -4.3373e-02, -2.2119e-01, -2.3598e-01, -2.6779e-01,\n",
       "                       -1.8555e-01,  1.1769e-01],\n",
       "                      [-2.8572e-01,  2.5669e-01, -8.7864e-02, -1.4566e-01,  2.7833e-01,\n",
       "                       -1.4275e-01, -1.0094e-02,  2.3705e-01,  1.8225e-01, -1.8262e-01,\n",
       "                        2.6038e-01, -2.3255e-01],\n",
       "                      [-4.7940e-02, -2.0818e-01, -1.0647e-01,  7.4871e-02, -2.3538e-02,\n",
       "                       -4.7127e-02, -7.4086e-02, -6.5893e-02, -1.5469e-01, -4.8240e-04,\n",
       "                       -1.5126e-03,  1.6512e-02],\n",
       "                      [-2.2712e-01,  3.4014e-02, -2.5844e-01,  3.3443e-02,  1.0995e-02,\n",
       "                        1.4723e-01, -5.7902e-03,  1.7130e-01,  9.9827e-02,  5.3022e-02,\n",
       "                       -8.4973e-02,  7.7402e-02],\n",
       "                      [ 1.5973e-01, -9.6550e-02,  1.0810e-01,  1.9187e-01,  2.3411e-01,\n",
       "                       -1.4661e-01, -3.3247e-02, -2.8103e-02,  9.4799e-02,  5.6129e-02,\n",
       "                        1.3922e-01, -1.0777e-01],\n",
       "                      [-7.2729e-02,  9.8433e-02, -2.4815e-02, -1.9159e-01, -9.1702e-02,\n",
       "                       -2.3679e-01, -1.4645e-01,  6.9929e-02, -1.3645e-01, -2.3673e-01,\n",
       "                        1.8849e-01, -2.3427e-02],\n",
       "                      [-1.2817e-02,  8.5349e-02, -2.4959e-01,  7.5545e-03, -2.5396e-01,\n",
       "                        5.8603e-02, -3.8420e-02,  2.7881e-01, -2.8321e-01, -2.7397e-01,\n",
       "                        8.0152e-02, -1.1815e-01],\n",
       "                      [-2.1514e-01, -1.0489e-01, -2.5874e-01, -1.0276e-01,  4.3258e-02,\n",
       "                        2.3050e-01, -1.4432e-01,  1.0267e-01, -1.0323e-01,  2.6553e-01,\n",
       "                        6.0152e-02, -1.6056e-01],\n",
       "                      [ 2.8656e-01,  1.0370e-03,  2.7672e-01, -2.3611e-02,  7.5120e-02,\n",
       "                       -2.8405e-01,  2.8560e-01,  1.6054e-01,  1.6165e-01, -1.5193e-01,\n",
       "                       -1.5469e-01,  1.1007e-01],\n",
       "                      [-3.2614e-02, -5.1673e-02,  1.2886e-01,  1.1190e-01, -3.3358e-02,\n",
       "                       -1.6031e-01,  1.2139e-02,  8.5150e-02, -9.6292e-02,  9.3708e-02,\n",
       "                       -2.4026e-01,  7.9726e-03],\n",
       "                      [ 5.2407e-02, -1.7682e-01,  4.9031e-02, -9.3088e-02,  1.5071e-01,\n",
       "                        2.6663e-01,  4.9439e-02,  1.9983e-01,  6.0068e-02, -2.5770e-01,\n",
       "                       -1.8923e-01,  1.8517e-02],\n",
       "                      [-1.0707e-01,  2.4074e-02,  2.6038e-01,  1.3661e-01,  3.4748e-02,\n",
       "                        1.3723e-01, -7.4849e-02,  1.6823e-01, -1.5356e-01,  1.7874e-01,\n",
       "                       -9.7123e-02,  9.5783e-02],\n",
       "                      [ 1.7119e-01, -1.6944e-01,  1.4028e-01,  9.6554e-02,  2.8488e-01,\n",
       "                        2.4840e-01, -2.3683e-01, -2.2085e-01, -1.7004e-01, -3.4636e-02,\n",
       "                       -9.7497e-02, -1.8448e-01],\n",
       "                      [ 1.4611e-02, -2.8819e-01, -3.8439e-02,  2.3866e-01, -2.1373e-01,\n",
       "                        1.4972e-01,  2.3661e-01,  7.8943e-02,  1.5754e-01,  1.3961e-02,\n",
       "                        4.1288e-02, -4.2756e-02],\n",
       "                      [ 1.9550e-01, -8.0693e-02,  2.7296e-01, -1.0120e-01, -4.3244e-02,\n",
       "                       -4.5160e-02,  9.7885e-02, -1.5951e-01, -2.3307e-01, -2.0179e-01,\n",
       "                        3.1009e-03, -2.9917e-02],\n",
       "                      [-5.8749e-02, -2.1212e-01,  2.1648e-01,  6.2191e-03,  2.1216e-01,\n",
       "                        2.6052e-01,  7.4716e-02, -2.1641e-01, -2.1064e-01, -2.3008e-01,\n",
       "                        1.5168e-01, -8.3386e-02],\n",
       "                      [ 2.7827e-01,  1.1033e-01,  2.7589e-01,  1.4935e-01,  8.6802e-02,\n",
       "                        5.9917e-02,  2.2038e-01, -2.1867e-01,  1.9427e-01,  2.5522e-01,\n",
       "                        2.0194e-01,  2.0226e-01],\n",
       "                      [-2.7382e-01,  5.5477e-02, -6.6374e-02,  1.8628e-02,  9.4859e-02,\n",
       "                        2.8185e-01,  1.9422e-01, -1.1752e-01, -1.1031e-01,  2.7068e-01,\n",
       "                        2.0590e-01, -4.1996e-02],\n",
       "                      [-1.9416e-01,  2.3369e-01, -2.6037e-01, -9.0877e-02, -5.6247e-02,\n",
       "                        1.3185e-01, -1.1759e-01, -2.4398e-01,  2.8110e-01,  2.8434e-01,\n",
       "                        1.0332e-01,  8.9303e-02],\n",
       "                      [ 2.6642e-01,  1.3620e-01, -8.7470e-02, -6.6144e-02,  4.4592e-02,\n",
       "                       -2.6950e-01, -5.7609e-02, -5.2802e-02, -1.3138e-01,  6.0314e-02,\n",
       "                        2.5873e-01,  2.3326e-01],\n",
       "                      [ 1.0899e-01, -6.9919e-02,  4.9966e-02,  1.9569e-01,  1.9868e-01,\n",
       "                        4.5532e-02,  1.7072e-01, -9.8075e-02, -5.3253e-02, -1.3271e-01,\n",
       "                       -1.4505e-01,  2.2336e-01],\n",
       "                      [-5.0387e-02,  2.6744e-01,  4.5939e-02, -5.2791e-02, -2.0872e-01,\n",
       "                        8.2584e-02, -4.9224e-02, -9.8504e-02, -1.7806e-01,  1.3154e-01,\n",
       "                       -2.0084e-01, -2.8253e-01],\n",
       "                      [ 2.5463e-02, -6.9324e-02,  1.7929e-01,  1.9279e-01, -2.9111e-02,\n",
       "                       -1.8357e-01,  2.2774e-01,  7.4771e-03,  1.3272e-01,  4.2271e-02,\n",
       "                        1.0927e-01,  2.1174e-01],\n",
       "                      [-7.5986e-02,  2.3620e-01, -1.0264e-01, -1.1829e-01, -1.5309e-01,\n",
       "                        2.0727e-01,  1.0926e-01,  5.5885e-02, -2.1785e-02, -2.4309e-01,\n",
       "                       -2.1700e-01, -1.9340e-01],\n",
       "                      [-1.3609e-01,  1.4284e-01, -1.3378e-01,  1.9589e-01,  5.5251e-02,\n",
       "                       -1.0204e-01,  2.7090e-01, -5.5495e-02, -2.5860e-01, -2.6200e-01,\n",
       "                        1.4858e-01,  6.3449e-02],\n",
       "                      [-1.9440e-01, -2.1798e-01, -5.4462e-02,  8.1904e-02, -2.4876e-01,\n",
       "                        1.8419e-01, -2.2910e-01,  1.3186e-01, -5.8045e-02, -1.7994e-02,\n",
       "                        7.3080e-02,  3.6318e-02],\n",
       "                      [-1.0324e-01,  2.2421e-01, -1.8217e-01,  1.7505e-02,  2.2949e-01,\n",
       "                        5.1203e-02,  1.0719e-01,  2.7852e-01,  2.4562e-02, -2.8616e-01,\n",
       "                       -7.5377e-02,  2.0106e-01],\n",
       "                      [ 2.2824e-01, -2.6990e-01, -2.4218e-02,  2.2686e-01,  1.4019e-03,\n",
       "                        1.3421e-01,  1.6432e-01,  1.6926e-01, -6.9528e-02,  2.6227e-01,\n",
       "                       -2.5845e-01,  5.6292e-02],\n",
       "                      [-2.5602e-01,  1.9961e-01, -2.6558e-01, -8.3676e-02, -2.7386e-01,\n",
       "                        1.7989e-01, -7.4948e-02, -2.0463e-01,  4.9544e-02,  2.1250e-01,\n",
       "                       -2.0188e-01, -1.7042e-01],\n",
       "                      [-2.0593e-01, -9.0862e-02,  2.6412e-01, -3.9292e-02, -2.8706e-01,\n",
       "                       -3.1608e-02,  5.7769e-02, -7.6963e-02,  2.6231e-01, -1.8659e-01,\n",
       "                        7.1870e-02, -1.0667e-01],\n",
       "                      [-1.5364e-01,  4.6778e-02,  1.7478e-01,  1.4339e-01, -2.0886e-01,\n",
       "                       -6.1628e-02,  2.8040e-01, -1.9886e-01,  4.2954e-02, -2.5092e-01,\n",
       "                       -2.2610e-01, -1.0310e-01],\n",
       "                      [-2.6186e-01,  2.1975e-01, -1.9830e-01,  8.9099e-02, -1.5448e-01,\n",
       "                       -1.0986e-02,  1.1878e-01, -1.0129e-03, -2.5609e-01, -1.3198e-01,\n",
       "                        1.5344e-01,  1.2546e-01],\n",
       "                      [ 2.0275e-01,  1.6283e-01, -1.0832e-01,  1.4899e-01,  1.9125e-01,\n",
       "                        1.4969e-01, -5.5196e-02,  1.7578e-01, -2.4860e-01, -1.3242e-01,\n",
       "                       -1.0317e-01, -5.6838e-02],\n",
       "                      [-1.5086e-01, -1.2002e-01,  2.3269e-01,  1.8865e-01,  1.4160e-01,\n",
       "                       -8.1123e-02,  1.9641e-01, -1.8456e-01, -9.0020e-02,  2.7285e-01,\n",
       "                        2.5895e-01,  2.2032e-01],\n",
       "                      [ 4.7141e-02,  2.3668e-01,  2.2826e-01, -6.1556e-02, -8.8673e-02,\n",
       "                       -9.2561e-02, -2.9524e-02,  2.5590e-01, -7.6842e-02, -2.4382e-01,\n",
       "                       -3.1406e-02,  2.1522e-01],\n",
       "                      [-2.8500e-01,  2.8717e-01, -2.2948e-01,  1.7185e-01, -5.3949e-02,\n",
       "                       -1.6361e-02,  4.3648e-02,  8.4246e-02, -2.4932e-01,  2.8639e-01,\n",
       "                        1.0325e-01,  1.0520e-04],\n",
       "                      [ 1.2926e-01,  1.7234e-02, -5.3643e-02,  2.3709e-01, -1.2283e-02,\n",
       "                       -2.3066e-01,  1.2301e-01, -1.4116e-01, -8.9782e-02, -2.1241e-01,\n",
       "                        5.6542e-02, -1.7170e-01],\n",
       "                      [ 2.8217e-01,  1.2744e-01, -2.8576e-01, -1.9131e-01,  2.0893e-01,\n",
       "                       -4.2747e-02,  1.0762e-01, -2.4812e-02,  4.5942e-02, -1.4604e-01,\n",
       "                        2.4577e-01, -9.4229e-03],\n",
       "                      [-1.2924e-01,  3.1938e-02, -1.8791e-01,  1.6886e-01,  1.9036e-02,\n",
       "                        1.2315e-01, -5.4207e-02,  2.6488e-01,  2.5978e-01,  2.4519e-02,\n",
       "                       -9.8471e-02,  1.9239e-01],\n",
       "                      [-1.5470e-01,  1.5454e-01,  2.1639e-01, -2.1036e-01,  1.5393e-01,\n",
       "                       -6.1167e-02,  7.6080e-02,  9.1430e-02,  4.2606e-02, -1.3891e-01,\n",
       "                        1.2783e-02, -2.1660e-01],\n",
       "                      [-1.3728e-01,  6.7578e-03, -2.2385e-01,  2.2620e-01,  1.1443e-01,\n",
       "                       -2.0294e-01,  2.6890e-01,  1.9912e-01,  1.4991e-01, -3.6578e-02,\n",
       "                        1.6766e-01,  1.3714e-01],\n",
       "                      [ 5.0269e-02,  1.9819e-01,  2.2582e-01, -8.0310e-02,  2.4671e-01,\n",
       "                       -2.8492e-01,  1.9597e-01,  2.0140e-01, -1.8668e-01, -7.5161e-02,\n",
       "                        5.3582e-02,  2.3315e-01],\n",
       "                      [ 2.7654e-01, -4.6037e-02, -1.5714e-02,  1.7553e-01, -1.0179e-02,\n",
       "                        1.8156e-01,  2.6708e-01, -1.0605e-01, -2.4541e-01, -1.2819e-01,\n",
       "                        1.0663e-01,  2.0991e-01],\n",
       "                      [ 7.7851e-02,  2.0958e-01,  5.4746e-02,  1.4752e-01,  2.7741e-01,\n",
       "                       -4.9712e-02, -1.1769e-01,  2.1809e-01,  6.7431e-02,  1.9062e-01,\n",
       "                        2.6309e-01, -6.2464e-02],\n",
       "                      [-2.6015e-01,  1.7524e-01,  2.1799e-01, -8.3336e-02, -5.5194e-02,\n",
       "                       -1.3877e-01, -1.6644e-01,  1.5404e-02,  2.2593e-01, -2.2815e-01,\n",
       "                        1.2100e-01,  5.2345e-02],\n",
       "                      [-3.3008e-02,  4.7491e-02, -2.6764e-01, -1.5019e-01,  9.8178e-02,\n",
       "                       -2.3658e-01,  5.8276e-02,  2.3718e-01,  3.7126e-02,  1.1625e-01,\n",
       "                        1.3728e-02,  3.4528e-02],\n",
       "                      [-1.1407e-01,  9.7693e-02, -8.5397e-02,  1.6106e-01,  2.4252e-02,\n",
       "                        1.5052e-01,  8.4154e-03, -5.3731e-03,  2.0434e-01, -2.8818e-01,\n",
       "                       -2.2500e-01, -5.9851e-02],\n",
       "                      [-8.5982e-02, -2.3019e-01, -9.5392e-02, -1.1542e-01,  9.9834e-02,\n",
       "                       -2.8498e-01,  6.3937e-02,  2.6164e-01, -2.5593e-02,  1.4843e-01,\n",
       "                       -8.1134e-02, -6.9017e-03],\n",
       "                      [ 2.0095e-01,  1.1519e-01,  1.2175e-01, -2.0403e-01, -8.9634e-02,\n",
       "                       -1.5114e-01, -1.1217e-01, -2.6760e-01,  3.6863e-02, -1.4379e-01,\n",
       "                        7.6230e-02,  2.5323e-01],\n",
       "                      [-5.9975e-02,  2.2043e-01,  1.5803e-01, -6.4617e-02,  2.2208e-02,\n",
       "                       -2.3223e-01, -2.7133e-01,  1.1877e-01, -1.9704e-01, -2.5531e-01,\n",
       "                       -8.4849e-02, -2.3978e-01],\n",
       "                      [ 7.2995e-02, -2.3760e-01, -3.1888e-02,  2.1786e-01, -1.3275e-02,\n",
       "                       -2.0464e-01,  1.7966e-01, -1.3709e-01, -2.6848e-01,  1.4743e-01,\n",
       "                        1.0504e-02, -1.8820e-02],\n",
       "                      [-2.7418e-02, -4.9706e-02,  5.3349e-02,  2.0271e-01, -7.8540e-02,\n",
       "                        2.0073e-01,  1.5572e-01,  2.5056e-01,  2.8001e-01,  1.9361e-01,\n",
       "                       -7.8989e-02, -2.4469e-01],\n",
       "                      [ 4.6257e-02,  1.0973e-01,  1.1164e-01,  1.3504e-01,  6.2979e-02,\n",
       "                       -9.7334e-02,  2.6311e-01,  8.7770e-03,  3.1647e-03, -1.8064e-01,\n",
       "                        5.5549e-03,  9.2955e-02],\n",
       "                      [-7.4936e-02,  2.0336e-01,  1.1999e-01, -8.5033e-02, -2.4151e-01,\n",
       "                       -7.9854e-02,  2.1707e-01, -2.7856e-01,  2.4265e-01, -6.2316e-02,\n",
       "                       -1.7430e-01,  2.8859e-01],\n",
       "                      [ 1.2073e-01,  1.6891e-01, -1.0608e-01, -2.1056e-01,  2.0414e-01,\n",
       "                       -9.5925e-02, -1.7117e-02, -2.4489e-01,  2.6302e-01, -2.6209e-01,\n",
       "                        2.1369e-01, -2.2531e-01],\n",
       "                      [ 4.1274e-02, -8.1749e-03,  2.7768e-02,  2.4521e-01, -1.0536e-01,\n",
       "                        5.9746e-02,  5.4127e-02,  4.9055e-02, -1.2463e-01, -2.8345e-01,\n",
       "                       -1.2164e-01,  5.7656e-02],\n",
       "                      [-1.5995e-01,  2.0926e-02,  1.7130e-01, -4.6283e-02,  8.5047e-02,\n",
       "                        2.7495e-01,  9.7692e-02,  1.6514e-01,  3.6958e-02, -9.2035e-02,\n",
       "                        2.7039e-02, -8.8901e-02],\n",
       "                      [-1.9321e-01,  2.2972e-01,  1.8314e-02, -2.1418e-01, -1.2440e-01,\n",
       "                       -1.6311e-01,  2.4208e-01, -2.6630e-01, -4.5942e-02, -2.0623e-01,\n",
       "                        3.4464e-02, -1.1544e-01],\n",
       "                      [ 2.1326e-01, -2.4091e-01,  1.3922e-01, -1.7727e-01,  3.9073e-02,\n",
       "                       -2.5437e-01, -2.7954e-01, -6.3067e-02, -4.8475e-02, -1.1356e-01,\n",
       "                        2.8532e-01, -8.5919e-02],\n",
       "                      [ 2.1775e-01, -1.9130e-01,  1.3962e-01, -1.2263e-03,  5.5379e-02,\n",
       "                        1.3500e-01, -1.4399e-02,  1.4755e-01,  4.0750e-02, -4.0167e-02,\n",
       "                        4.8728e-02, -6.5730e-02],\n",
       "                      [ 1.2474e-01, -1.7843e-01, -1.5325e-01,  1.7604e-01, -1.8423e-02,\n",
       "                       -1.0086e-01,  2.2545e-01, -1.0108e-02,  2.1551e-01, -1.3718e-02,\n",
       "                        5.3059e-02, -2.8018e-01]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.0619, -0.0413, -0.1404, -0.1452, -0.2299,  0.0855,  0.0153, -0.1179,\n",
       "                      -0.1682,  0.0524,  0.1220,  0.0032,  0.2562,  0.1230,  0.1050, -0.0627,\n",
       "                       0.1943, -0.1302, -0.2416,  0.0963,  0.0061,  0.2245,  0.0587,  0.2253,\n",
       "                       0.1172,  0.1728, -0.2535, -0.1689, -0.2181, -0.1950,  0.1086, -0.0893,\n",
       "                      -0.1651,  0.0387,  0.0749,  0.1099, -0.0511, -0.0054, -0.0748,  0.0564,\n",
       "                      -0.2468, -0.2640,  0.0326, -0.0684,  0.1348, -0.0053,  0.2178,  0.2838,\n",
       "                      -0.2279, -0.1351, -0.0669,  0.2340, -0.1760, -0.1929,  0.0927, -0.1022,\n",
       "                      -0.0403, -0.1321, -0.1645,  0.0357, -0.1061,  0.2185,  0.0236,  0.1393])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0342, -0.0585,  0.1118,  ...,  0.0539,  0.0458, -0.1113],\n",
       "                      [-0.0160,  0.0125, -0.0119,  ...,  0.0144, -0.0913,  0.0052],\n",
       "                      [ 0.0578, -0.0073,  0.0485,  ...,  0.0593, -0.0649,  0.0170],\n",
       "                      ...,\n",
       "                      [-0.0701, -0.1005,  0.1053,  ..., -0.1016, -0.0938,  0.0242],\n",
       "                      [ 0.0066, -0.0801,  0.0785,  ...,  0.0580, -0.0787,  0.0506],\n",
       "                      [-0.0431,  0.0079, -0.0600,  ..., -0.0347,  0.0477, -0.1160]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([-0.0964,  0.0047,  0.1157, -0.0346, -0.0017, -0.0695, -0.0674,  0.0225,\n",
       "                       0.0613,  0.0631,  0.0375,  0.0864,  0.0868, -0.0352,  0.0137,  0.1156,\n",
       "                      -0.1070,  0.1136,  0.0400,  0.0116, -0.0253, -0.1247,  0.0091,  0.0741,\n",
       "                      -0.0238,  0.0458,  0.0432,  0.0756,  0.0862, -0.0340,  0.0488, -0.1118,\n",
       "                      -0.0616,  0.0420, -0.0788,  0.0478,  0.0461,  0.0730,  0.1246, -0.0206,\n",
       "                       0.0942,  0.0145,  0.0150,  0.0963,  0.0423,  0.0580,  0.0180, -0.1014,\n",
       "                       0.0646, -0.1177,  0.0278, -0.0164, -0.1006, -0.0697, -0.0605,  0.0165,\n",
       "                       0.0132,  0.0673, -0.0247,  0.0301, -0.0900,  0.0340, -0.0974,  0.0626])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 0.0938,  0.0489,  0.0213,  0.0504, -0.1048,  0.0235,  0.0200, -0.0666,\n",
       "                        0.0574,  0.0724, -0.0381, -0.1114,  0.0375,  0.0940,  0.0168, -0.0021,\n",
       "                       -0.1184, -0.0414, -0.0730,  0.0942,  0.0782,  0.0238,  0.1002,  0.1156,\n",
       "                        0.1123, -0.0429, -0.0609,  0.0851, -0.0850,  0.1151, -0.0330,  0.1027,\n",
       "                        0.0988, -0.1243, -0.0976, -0.1136, -0.0594,  0.1026, -0.0714, -0.1071,\n",
       "                        0.1225,  0.0593, -0.0824, -0.0346,  0.0124, -0.1164,  0.0931,  0.0951,\n",
       "                       -0.0115, -0.0390,  0.0286,  0.0312,  0.0960,  0.0081, -0.0166,  0.1228,\n",
       "                        0.0494, -0.1150,  0.0149,  0.0536, -0.0850, -0.1111, -0.0962, -0.0401]])),\n",
       "             ('fc3.bias', tensor([0.0818]))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93a862ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(self, training_set):\n",
    "    # training_set = (observation, action, reward)\n",
    "    net.train()\n",
    "    for batch_idx, (observation, action, reward) in enumerate(training_set):\n",
    "        if not observation.any():\n",
    "            observation = env.reset()[0]\n",
    "#             print(env.reset()[0])\n",
    "        self.optimizer.zero_grad()\n",
    "#             print('obs', observation)\n",
    "#             print('act', action)\n",
    "        actions = [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]]\n",
    "        output = self.net.forward(torch.cat((torch.tensor(observation), torch.tensor(actions[action]))))\n",
    "        print('out', type(output))\n",
    "        print('out', type(reward))\n",
    "        mse_loss = torch.nn.MSELoss()\n",
    "        loss = mse_loss(output.float(), torch.tensor(reward).float())\n",
    "#             loss = (output - torch.tensor(reward)) ** 2\n",
    "        print('loss: ', loss)\n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e95d5c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.9415, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.train()\n",
    "optimizer.zero_grad()\n",
    "output = net.forward(x[0])\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "loss = mse_loss(output.float(), torch.tensor([Y[0]]).float())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "bb7fd668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[-1.3463e-02, -1.1302e-01,  1.1833e-01,  1.5934e-01, -1.4481e-01,\n",
       "                        1.9278e-02,  5.8472e-03,  1.7347e-02, -1.7847e-01,  2.9396e-01,\n",
       "                       -1.9041e-01, -2.5413e-01],\n",
       "                      [-1.4057e-01,  2.4673e-01, -2.7209e-01,  6.5824e-02, -1.5905e-01,\n",
       "                       -1.1864e-01, -6.2448e-02, -1.9720e-01,  1.3977e-01,  1.6447e-01,\n",
       "                        1.3674e-01,  1.2196e-01],\n",
       "                      [-1.5453e-01,  1.3623e-01,  1.6598e-01,  9.7330e-03,  2.4782e-01,\n",
       "                        1.0478e-01, -5.9850e-02, -1.0302e-02,  1.1173e-02,  4.0694e-02,\n",
       "                        7.4308e-02,  1.0791e-01],\n",
       "                      [ 5.9213e-02,  2.0140e-03,  1.7098e-01, -1.3732e-01, -3.6753e-05,\n",
       "                       -2.3770e-01, -1.9406e-01, -2.9072e-02,  1.6242e-01, -2.3423e-01,\n",
       "                       -2.7880e-01, -2.3202e-02],\n",
       "                      [-2.1525e-01, -1.6945e-01,  2.6424e-01, -8.8436e-02,  4.0080e-02,\n",
       "                       -1.1251e-01, -8.4662e-04, -5.1624e-02,  3.4396e-02,  8.2242e-02,\n",
       "                        2.8313e-02,  1.3222e-01],\n",
       "                      [ 2.5811e-01,  2.2880e-01, -2.6870e-01, -1.5930e-01,  1.1865e-01,\n",
       "                        1.2235e-01, -2.1389e-01,  2.4704e-01,  1.2480e-01,  1.1977e-01,\n",
       "                       -1.0489e-01, -2.7423e-01],\n",
       "                      [-3.7211e-02, -6.3269e-02, -2.4067e-01,  7.1043e-02,  7.1802e-02,\n",
       "                        9.2805e-02,  9.6401e-02, -1.0460e-01,  7.9358e-02,  2.2368e-01,\n",
       "                       -8.4922e-02,  2.6209e-01],\n",
       "                      [ 4.6921e-02, -8.1770e-02,  2.7223e-01,  1.6703e-01, -1.7007e-01,\n",
       "                       -2.6179e-01,  3.3452e-02, -6.2672e-02,  2.6269e-01, -9.5648e-02,\n",
       "                        2.5528e-01, -2.3480e-01],\n",
       "                      [ 2.2916e-01, -1.2520e-01, -2.7169e-01,  1.8189e-01, -8.0615e-02,\n",
       "                        2.4577e-01, -2.5416e-01, -1.1573e-01,  1.9007e-01,  1.9332e-01,\n",
       "                       -3.4749e-02, -1.3957e-01],\n",
       "                      [ 7.9390e-02,  2.2617e-01, -1.1462e-01, -7.7845e-02, -6.1042e-02,\n",
       "                       -6.7817e-03, -2.3747e-01, -1.1338e-01, -5.2028e-02,  1.8459e-01,\n",
       "                        1.4597e-01, -2.0861e-01],\n",
       "                      [ 1.4402e-01, -1.8512e-01, -1.0154e-01, -9.7086e-02,  9.6935e-02,\n",
       "                        1.2165e-01, -1.7861e-01, -1.7942e-01,  2.2719e-01,  2.5089e-01,\n",
       "                        4.3082e-02,  2.0713e-01],\n",
       "                      [-1.4485e-01,  2.9293e-01,  1.8351e-01, -6.8035e-02, -1.7418e-01,\n",
       "                       -2.1255e-01, -1.7268e-01, -4.5450e-02, -1.0604e-01,  1.1623e-01,\n",
       "                        1.4013e-01, -1.6124e-02],\n",
       "                      [-5.1492e-02, -2.5280e-01, -1.8288e-01, -1.7342e-01, -2.6322e-01,\n",
       "                       -7.8471e-02, -2.2048e-01, -4.2806e-02,  2.7811e-02, -2.2771e-01,\n",
       "                       -4.8240e-02, -2.5776e-01],\n",
       "                      [ 2.5026e-01,  1.9810e-01,  1.0407e-01,  9.1057e-02,  5.9643e-02,\n",
       "                        1.5049e-01,  2.6418e-01,  8.2658e-02, -2.1064e-01,  6.5926e-02,\n",
       "                        5.5245e-02,  8.2327e-02],\n",
       "                      [ 2.3588e-01, -1.0904e-01, -9.8438e-02, -1.3587e-01,  9.6561e-02,\n",
       "                       -1.2532e-01,  2.1318e-01,  2.4474e-01, -3.9546e-02, -1.4297e-01,\n",
       "                        1.7386e-01,  2.6558e-01],\n",
       "                      [-1.3043e-01, -2.5540e-01,  1.6013e-01, -2.0423e-01,  1.1127e-01,\n",
       "                       -5.2745e-02, -4.9095e-02, -2.1115e-01,  1.3315e-01,  1.7632e-01,\n",
       "                        2.6145e-02,  2.4573e-02],\n",
       "                      [ 4.8440e-02, -4.9325e-02, -1.0027e-01,  1.6293e-01, -5.3841e-02,\n",
       "                        1.8495e-01, -7.3908e-02, -1.0746e-01, -2.6438e-01,  7.4011e-03,\n",
       "                        1.3709e-02, -1.9464e-01],\n",
       "                      [ 1.8986e-01, -1.8085e-01,  2.1505e-01, -1.8501e-01, -1.0693e-02,\n",
       "                        1.0333e-01,  2.5572e-01, -9.2150e-02, -3.7746e-02,  3.2324e-02,\n",
       "                       -1.1578e-01,  2.0519e-01],\n",
       "                      [ 2.0017e-02,  1.2457e-01,  2.3833e-01,  5.7673e-03, -1.6701e-02,\n",
       "                       -1.2108e-01, -1.7587e-01, -1.2597e-01, -2.1263e-01, -2.5739e-01,\n",
       "                        2.5397e-01,  1.4430e-01],\n",
       "                      [ 1.2231e-02,  2.4032e-02, -2.5093e-01, -2.5630e-01, -1.2413e-01,\n",
       "                        1.7406e-01, -7.0045e-02,  2.6572e-01, -2.0901e-01,  2.6053e-01,\n",
       "                       -5.8769e-02,  1.1619e-01],\n",
       "                      [-1.3688e-01,  1.5243e-01, -1.8195e-01, -1.8537e-01,  1.0493e-01,\n",
       "                        4.2293e-02,  1.2300e-01,  1.0130e-01, -2.2913e-01, -1.6635e-01,\n",
       "                        3.2092e-02, -2.6947e-01],\n",
       "                      [ 1.0252e-01, -2.0777e-03,  2.0023e-01,  1.4151e-02, -3.0306e-02,\n",
       "                        2.0494e-01, -1.2551e-02,  9.4346e-02, -2.0070e-01,  1.6278e-01,\n",
       "                       -1.7543e-01,  1.4269e-01],\n",
       "                      [ 4.1307e-03, -3.7683e-02,  2.7032e-01, -2.0337e-01,  2.2049e-01,\n",
       "                        2.0239e-01, -8.4161e-02, -2.1650e-01,  1.9227e-01,  1.4767e-01,\n",
       "                        2.8253e-01,  3.5691e-02],\n",
       "                      [-6.9881e-02, -1.3027e-01, -1.7477e-01, -2.5528e-01, -2.6258e-01,\n",
       "                        1.5364e-01, -8.5824e-02, -2.8107e-01,  7.6646e-03, -2.3015e-02,\n",
       "                       -2.2953e-01, -2.8304e-01],\n",
       "                      [-2.5291e-01,  2.0264e-02, -1.0232e-01,  6.6920e-02, -1.6295e-01,\n",
       "                       -2.3966e-01,  2.3025e-01, -7.0711e-02,  1.2880e-01, -7.6393e-03,\n",
       "                        2.4498e-01, -2.8501e-01],\n",
       "                      [-1.1234e-02, -1.6147e-01,  1.7903e-01, -4.9338e-02, -1.4350e-01,\n",
       "                       -1.0075e-01,  8.7876e-02, -1.0964e-01, -1.9895e-01,  4.1963e-02,\n",
       "                       -1.8622e-01, -2.7974e-02],\n",
       "                      [ 1.1168e-01, -8.8018e-02,  1.6738e-01,  2.3081e-01,  1.1571e-03,\n",
       "                        2.6026e-01, -2.9653e-02, -7.2410e-02,  3.2773e-02,  2.3548e-01,\n",
       "                        1.2185e-01,  1.8118e-01],\n",
       "                      [-1.7199e-01,  1.4997e-01,  8.4523e-02,  4.8046e-02, -6.3498e-02,\n",
       "                        2.9022e-02,  1.8418e-01, -2.4055e-01, -1.0324e-01,  6.5183e-02,\n",
       "                       -9.9304e-02,  1.4247e-01],\n",
       "                      [-3.6113e-02, -1.9676e-01, -1.7442e-01, -5.5781e-02,  1.4844e-01,\n",
       "                        1.8088e-01,  1.9651e-02,  3.5567e-02,  6.2201e-03, -6.5299e-03,\n",
       "                       -1.1334e-01, -4.7655e-02],\n",
       "                      [ 1.0923e-01,  2.7369e-02,  2.5485e-01,  1.7690e-01, -2.7548e-01,\n",
       "                        1.2520e-01,  1.7822e-01, -2.1096e-01, -1.2180e-01,  1.9459e-01,\n",
       "                       -2.5170e-01, -5.7407e-02],\n",
       "                      [ 2.4974e-02, -1.1722e-01,  1.0314e-01, -4.9176e-02,  5.0318e-02,\n",
       "                        2.5164e-01, -1.9264e-01,  1.0570e-01,  1.9884e-01, -2.4701e-01,\n",
       "                        1.4444e-01,  3.8451e-02],\n",
       "                      [-2.2240e-01,  7.0541e-02,  1.5457e-01,  1.7513e-01,  1.8384e-01,\n",
       "                       -7.4344e-02, -3.1431e-02, -5.3137e-02, -9.9978e-02,  7.3032e-02,\n",
       "                       -2.2886e-01,  1.6189e-01],\n",
       "                      [ 1.9886e-01, -8.9367e-02,  4.4942e-02, -3.4983e-02, -6.4809e-02,\n",
       "                       -1.9769e-01, -2.7176e-01,  7.6548e-02,  3.6657e-02, -1.7725e-01,\n",
       "                       -1.7244e-01,  2.0920e-01],\n",
       "                      [-2.5057e-01,  5.2794e-02, -1.0402e-01,  1.7775e-02, -1.4765e-01,\n",
       "                       -2.3402e-01, -1.3606e-01, -1.9084e-01, -2.4785e-01, -2.5968e-01,\n",
       "                        2.3060e-02, -2.6156e-01],\n",
       "                      [-1.4815e-03,  1.6313e-01,  2.3132e-01,  1.2804e-01, -1.7100e-01,\n",
       "                        2.2388e-01, -1.9425e-01, -2.2413e-01,  1.0679e-01,  2.8291e-01,\n",
       "                        1.3221e-01,  1.4776e-01],\n",
       "                      [ 2.3483e-01,  5.3626e-02, -1.6485e-01,  7.0012e-02,  2.7801e-01,\n",
       "                       -1.1229e-01,  9.1315e-02, -2.3228e-01,  1.2368e-01,  3.5993e-02,\n",
       "                        6.7094e-02,  1.8349e-01],\n",
       "                      [-1.8421e-01,  8.9279e-02, -5.6278e-02,  7.9811e-02, -3.2293e-02,\n",
       "                        2.2619e-01, -7.5924e-02,  5.7501e-02,  2.3804e-01,  1.8459e-01,\n",
       "                        1.2040e-01,  2.2628e-01],\n",
       "                      [ 2.7327e-01, -2.4573e-01, -4.0946e-02, -1.8884e-01,  2.0074e-01,\n",
       "                       -2.5380e-01, -8.2237e-02,  1.2732e-02,  2.2524e-01,  2.2416e-01,\n",
       "                       -3.5747e-02,  1.9702e-01],\n",
       "                      [-1.2167e-02,  1.5559e-01,  8.1127e-02,  1.6350e-02,  1.7495e-01,\n",
       "                       -2.2373e-01,  2.8566e-02, -1.0044e-01,  3.1473e-02,  1.5224e-01,\n",
       "                        2.8421e-01,  2.6493e-01],\n",
       "                      [ 3.5338e-02,  4.6766e-03, -8.7032e-02,  5.7149e-02, -8.2919e-02,\n",
       "                       -2.5195e-01,  1.7899e-01, -1.8532e-01,  1.5201e-01, -2.1594e-01,\n",
       "                       -4.2557e-02, -1.1992e-02],\n",
       "                      [ 1.8012e-01,  6.5811e-02, -1.8448e-01,  1.5317e-01, -1.8169e-01,\n",
       "                        1.7434e-01, -1.8114e-01,  1.4728e-01, -2.1738e-01,  1.3631e-02,\n",
       "                       -2.1565e-01, -1.9900e-01],\n",
       "                      [-1.0647e-01, -1.1304e-01,  2.1261e-01,  1.8078e-01, -1.8385e-01,\n",
       "                        2.7536e-01, -1.6279e-01, -1.3085e-01,  3.0599e-02,  2.2133e-01,\n",
       "                        1.4137e-01, -4.6051e-02],\n",
       "                      [-1.2988e-01,  2.2767e-01, -1.1094e-01, -2.7871e-01, -9.9962e-02,\n",
       "                       -1.6029e-01,  1.9793e-01, -2.8839e-01, -1.3460e-02, -1.6283e-02,\n",
       "                       -1.7261e-01, -4.9525e-02],\n",
       "                      [-1.3996e-01, -1.9608e-02,  6.6679e-02,  5.4132e-03, -6.0667e-02,\n",
       "                       -1.6812e-01,  2.4986e-01, -2.3113e-01, -4.9847e-02,  4.4391e-02,\n",
       "                       -2.0713e-01,  2.4563e-01],\n",
       "                      [ 2.6924e-01, -3.2179e-02, -2.7084e-02,  2.3116e-01,  2.4391e-01,\n",
       "                       -2.0898e-01, -2.7463e-01,  6.4871e-03,  1.2707e-01, -9.7642e-02,\n",
       "                        5.7851e-02, -8.5942e-02],\n",
       "                      [ 2.6652e-02, -1.6198e-01,  8.7309e-03, -1.7432e-01,  1.2771e-01,\n",
       "                        1.6819e-01,  2.6976e-01,  1.1642e-01, -1.4215e-01, -5.9878e-02,\n",
       "                        1.6618e-01,  1.2580e-01],\n",
       "                      [ 2.4721e-01, -2.4280e-01,  9.8647e-03, -2.8843e-01,  2.8094e-01,\n",
       "                       -1.5074e-01,  1.2762e-02, -1.4098e-01,  1.0706e-01,  7.4294e-02,\n",
       "                       -2.3661e-01,  2.8230e-01],\n",
       "                      [-2.8022e-02,  7.7454e-02,  1.5286e-01, -2.3993e-01,  1.7110e-01,\n",
       "                       -2.2301e-01,  7.3261e-02, -1.9279e-01, -2.5201e-01,  2.6956e-02,\n",
       "                        8.2387e-02,  2.1609e-01],\n",
       "                      [-2.4613e-01, -1.1812e-01, -2.5696e-01, -2.4183e-01,  1.0977e-01,\n",
       "                       -8.6189e-02, -1.9580e-01,  1.9663e-01, -2.2148e-01,  1.5187e-01,\n",
       "                        1.6930e-01, -2.7076e-01],\n",
       "                      [-1.3168e-01,  1.0242e-01, -1.3730e-01, -2.8878e-01,  1.2862e-01,\n",
       "                       -1.7374e-01, -2.8170e-01, -6.2112e-02, -1.6302e-01,  5.1783e-02,\n",
       "                       -4.4769e-02,  9.2939e-02],\n",
       "                      [ 9.4875e-02, -2.7410e-01, -1.3596e-02, -2.0995e-01,  9.1036e-02,\n",
       "                        4.0163e-02,  1.9707e-01, -2.4090e-01,  1.0258e-01,  1.3643e-01,\n",
       "                        1.1089e-01,  8.3772e-02],\n",
       "                      [-8.3608e-02, -1.5024e-01, -1.5363e-01, -2.6719e-01, -1.1811e-01,\n",
       "                       -2.6227e-01,  2.5581e-01, -2.4276e-03,  4.2352e-02,  9.0243e-03,\n",
       "                        2.2891e-01, -1.0495e-02],\n",
       "                      [-5.3448e-02,  1.6752e-01, -7.5347e-02, -2.7819e-02,  7.0828e-02,\n",
       "                        2.3762e-01, -2.1743e-01, -6.2032e-02, -1.5361e-01,  1.6964e-01,\n",
       "                        2.0099e-01, -2.2663e-02],\n",
       "                      [ 1.1849e-01,  3.1779e-02,  9.6725e-02, -4.4763e-02, -3.1896e-02,\n",
       "                        2.6983e-02, -1.5441e-01, -8.9604e-02,  2.7489e-01,  2.4400e-01,\n",
       "                       -2.4684e-01,  2.2064e-01],\n",
       "                      [-1.3350e-01, -2.4755e-01,  2.1690e-01, -1.4676e-01, -8.2361e-02,\n",
       "                       -2.3936e-02,  2.3596e-01, -2.8416e-01, -1.9176e-01,  2.8514e-01,\n",
       "                        2.8191e-01,  1.7894e-01],\n",
       "                      [ 1.0211e-01, -2.2837e-01,  3.4137e-03, -1.7327e-01,  2.6185e-01,\n",
       "                        1.4777e-01,  1.7056e-01,  1.8590e-02, -8.3716e-02, -8.7196e-02,\n",
       "                        1.0813e-01, -8.1404e-02],\n",
       "                      [-5.1569e-03,  3.8431e-02, -4.5888e-02,  1.6415e-01, -1.1052e-01,\n",
       "                       -1.0111e-01, -7.9357e-02, -1.0002e-01,  2.3317e-01,  2.2425e-01,\n",
       "                        2.2934e-02,  1.6805e-01],\n",
       "                      [ 1.8531e-01,  5.4275e-02, -6.3508e-02,  7.0918e-02,  3.0531e-02,\n",
       "                       -2.5400e-01, -1.1966e-01,  2.3071e-01,  1.8946e-01,  2.2288e-02,\n",
       "                        1.7506e-01, -1.4088e-02],\n",
       "                      [-2.5221e-01, -6.8161e-02, -2.1983e-01, -1.5525e-02,  2.4317e-01,\n",
       "                       -4.9894e-03,  1.9575e-01,  5.5130e-02, -2.4530e-01, -2.0085e-01,\n",
       "                       -2.4140e-01, -7.9639e-02],\n",
       "                      [-2.8469e-01,  1.4844e-01,  1.7007e-01,  2.1726e-01, -5.0092e-02,\n",
       "                        3.2031e-02,  1.4994e-03,  2.2370e-01, -1.6642e-03,  2.8752e-01,\n",
       "                        1.4184e-01, -1.2626e-01],\n",
       "                      [ 1.0173e-01, -3.9830e-02, -4.0219e-02,  1.2481e-01, -9.4407e-02,\n",
       "                       -2.1816e-01, -1.2471e-01, -1.9769e-01,  8.4209e-02,  2.3302e-01,\n",
       "                        2.3654e-01,  4.6172e-02],\n",
       "                      [-1.7867e-01,  3.4791e-02, -1.4141e-02,  1.2216e-02,  2.6066e-01,\n",
       "                       -2.5271e-01,  8.3143e-02,  2.5089e-01,  9.9259e-02,  2.1871e-01,\n",
       "                       -1.8227e-01,  2.8002e-01],\n",
       "                      [-1.6317e-01,  2.2210e-01,  1.6215e-01, -1.4248e-01,  3.8578e-02,\n",
       "                       -1.4017e-01,  1.0217e-01, -2.3813e-01, -2.7802e-01, -1.8789e-01,\n",
       "                        1.8425e-01,  1.9767e-01],\n",
       "                      [ 1.5844e-01, -2.1529e-01, -2.8388e-01, -2.7893e-01,  1.6887e-01,\n",
       "                        2.4465e-01,  2.5795e-01,  1.5873e-01,  1.0995e-01, -2.6813e-01,\n",
       "                        2.5910e-01, -7.2802e-02]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.2553, -0.2223,  0.0190,  0.1132,  0.2050,  0.0357,  0.1467, -0.0669,\n",
       "                      -0.1503,  0.1167, -0.1219,  0.0329,  0.0410,  0.1157, -0.2071, -0.1899,\n",
       "                       0.1039,  0.0442, -0.1871, -0.0162,  0.1722,  0.1901,  0.0229, -0.0625,\n",
       "                      -0.2391,  0.0712, -0.1817, -0.0352, -0.0381, -0.2331, -0.0243,  0.2422,\n",
       "                       0.0846,  0.0684, -0.2124, -0.1677,  0.0040,  0.2389, -0.0574,  0.2301,\n",
       "                       0.1112,  0.0788, -0.0191,  0.1866, -0.1791,  0.0402,  0.0367,  0.2439,\n",
       "                       0.0991,  0.1185, -0.1626, -0.2478,  0.0913,  0.2606, -0.0342, -0.0535,\n",
       "                      -0.0191,  0.2946,  0.0486,  0.0327,  0.0876,  0.1026,  0.2496, -0.2531])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.0085, -0.0190, -0.0382,  ..., -0.0861,  0.0415,  0.0559],\n",
       "                      [-0.0288,  0.0858, -0.0859,  ...,  0.1099, -0.1167,  0.0321],\n",
       "                      [ 0.0734, -0.0799, -0.1081,  ...,  0.0878, -0.0110,  0.0248],\n",
       "                      ...,\n",
       "                      [-0.0243, -0.0821,  0.1068,  ...,  0.0956,  0.0409, -0.0523],\n",
       "                      [ 0.1195, -0.0118,  0.1100,  ...,  0.0504, -0.0010,  0.0754],\n",
       "                      [ 0.0115,  0.0765, -0.0467,  ..., -0.1143,  0.0520,  0.0052]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.0370, -0.0676, -0.0986, -0.0678, -0.0009,  0.1180, -0.1067,  0.1324,\n",
       "                      -0.0077, -0.0264, -0.1149,  0.0459, -0.0644, -0.0992,  0.0378,  0.0253,\n",
       "                       0.1101, -0.0896,  0.0096, -0.0833, -0.0734,  0.0096,  0.0836,  0.1043,\n",
       "                      -0.0632, -0.0320, -0.1009, -0.0015, -0.0568,  0.1052,  0.1016,  0.0800,\n",
       "                       0.1068,  0.1128, -0.0584,  0.0915, -0.0801, -0.0552, -0.0382,  0.0595,\n",
       "                      -0.1167, -0.0842,  0.1070,  0.0985,  0.0605, -0.0324,  0.0444, -0.0138,\n",
       "                      -0.1000, -0.0292, -0.0317, -0.1090, -0.0669, -0.0783, -0.0975,  0.1025,\n",
       "                      -0.0147, -0.0592, -0.1219, -0.0615, -0.0491,  0.1137,  0.1040, -0.0705])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 0.0725, -0.0303,  0.0053,  0.1199, -0.0392, -0.0159,  0.0277, -0.0465,\n",
       "                        0.0470, -0.0072,  0.0714,  0.0889,  0.0223, -0.0896, -0.0645,  0.0215,\n",
       "                        0.0280,  0.0129, -0.0186,  0.0919, -0.0036,  0.1083,  0.0255, -0.0869,\n",
       "                        0.0720,  0.0032, -0.1274,  0.0204,  0.0470,  0.0531,  0.0236,  0.0963,\n",
       "                       -0.1131,  0.0711,  0.0359,  0.0457, -0.1157, -0.0880,  0.1248,  0.1004,\n",
       "                        0.0694, -0.1114,  0.0491, -0.0475,  0.0709, -0.0912, -0.0534, -0.1051,\n",
       "                       -0.0867, -0.0926, -0.0263,  0.1150, -0.0435,  0.0970,  0.1002, -0.0458,\n",
       "                        0.0573,  0.0163, -0.0956, -0.0167, -0.0326, -0.0692, -0.0913,  0.0887]])),\n",
       "             ('fc3.bias', tensor([-0.0083]))])"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83b9a4af",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  tensor(2.5481, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(1.3912, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(1.1363, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.8916, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.8423, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.3656, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.2389, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.4511, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.3133, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.0107, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.0571, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.0082, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.0008, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.0037, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.0617, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.1997, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.2698, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.3004, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.2767, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.3844, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.0241, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.0052, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.0001, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.0086, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.0263, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.0688, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.1138, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.1637, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.2184, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.2751, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.0233, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.2015, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(1.7524e-05, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.0935, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.1062, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.1713, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.0029, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.1234, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.3154, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.2701, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.7845, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.8028, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(1.4480, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(2.0339, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(2.6409, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(2.4178, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(2.6961, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(2.5927, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(3.3595, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(3.3440, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(3.8220, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(3.6516, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(3.1506, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(2.2521, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(1.9281, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(1.1777, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.5781, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(0.1077, grad_fn=<MseLossBackward0>)\n",
      "loss:  tensor(8613.5176, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9429/615601549.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xx = torch.tensor(xx, dtype=torch.float32)\n",
      "/tmp/ipykernel_9429/615601549.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = mse_loss(output.float(), -torch.tensor(YY).float())\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "for i in range(1):\n",
    "    for xx, YY in zip(x, Y): \n",
    "        xx = torch.tensor(xx, dtype=torch.float32)\n",
    "        YY = torch.tensor(YY, dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(xx)\n",
    "        mse_loss = torch.nn.MSELoss()\n",
    "        loss = mse_loss(output.float(), -torch.tensor(YY).float())\n",
    "        print('loss: ', loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5b95218c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.7126)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9429/4100603711.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  xx = torch.tensor(xx, dtype=torch.float32)\n",
      "/tmp/ipykernel_9429/4100603711.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  loss = mse_loss(output.float(), -torch.tensor(YY).float())\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "for i in range(1):\n",
    "    loss_mean = []\n",
    "    for xx, YY in zip(x, Y): \n",
    "        xx = torch.tensor(xx, dtype=torch.float32)\n",
    "        YY = torch.tensor(YY, dtype=torch.float32)\n",
    "        optimizer.zero_grad()\n",
    "        output = net(xx)\n",
    "        mse_loss = torch.nn.MSELoss()\n",
    "        loss = mse_loss(output.float(), -torch.tensor(YY).float())\n",
    "        loss_mean.append(loss)\n",
    "#         print('loss: ', loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(torch.tensor(loss_mean).sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
